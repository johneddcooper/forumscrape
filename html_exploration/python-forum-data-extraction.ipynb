{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will go through the process of examining a forum webpage for the data we want to extract, and the HTML tags and properties that we can use to identify that data.\n",
    "\n",
    "For the main program, we intend to use Scrapy to fetch the web pages and extract the data, for simplicity during exploration we only use Scrapy to extract the data and use requests to fetch the website we are interested in.\n",
    "\n",
    "It might be useful to illustrate what is happening if you open the below \"thread_url\" in a separate tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-fe7f837f0393>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkup\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mremove_tags\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'date'"
     ]
    }
   ],
   "source": [
    "# import requests to fetch the website (there are many ways of doing this)\n",
    "import requests\n",
    "# import scrapy to develop the Selectors that extract the data we want, to prove they work\n",
    "import scrapy\n",
    "from pprint import pprint\n",
    "# we import scrapy.selector as Selector and remove_tags for use later\n",
    "from scrapy.selector import Selector\n",
    "from scrapy.utils.markup import remove_tags\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the page from the test forum that I will use to explore the data. \n",
    "# The selectors should be tried against multiple web pages to catch inconsistencies, especially is the site had\n",
    "# complex mechanics like quotes, code blocks, and other forms of media. \n",
    "thread_url = \"https://learningautomaton.ca/wp-content/uploads/2019/02/FruitsAndVeggiesForum/Knock%20Knock...%20-%20Fruits%20and%20Veggies.html\"\n",
    "# use requests to fetch the page as a requests object\n",
    "request_file = requests.get(thread_url)\n",
    "\n",
    "# extract the raw html (the \"text\" property) from the requests object\n",
    "thread_html_text = request_file.text\n",
    "# note that the two steps could be combined for brevity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool that scrapy uses to extract a particular part of an html response is Selectors, which are used to select a certin part of the html file.\n",
    "Scrapy Selectors are built on the [lxml](http://lxml.de/) XML and HTML parsing library, and is fairly fast.\n",
    "\n",
    "We also make use of xpath strings. Xpath strings are one method of navigating through an html text to a particular\n",
    "tag (the other being [CSS expressions](https://www.w3.org/TR/selectors/)). \n",
    "\n",
    "Xpath has a number of options, however the key characters we will be using are:\n",
    "\n",
    "`/tag_name` : from the tag we are at, search for a tag that is an immidiate child that is called `tag_name`\n",
    "`//tag_name` : from the tag we are at, search for all contained tags that are called `tag_name`\n",
    "`@property_name` : extract the value of the tag property called `property_name` from the tag we are currently at\n",
    "`/tag_name[@property_name='property_value']` : go to a child tag that has a property called `property_name` and a value of `property_value`\n",
    "\n",
    "These key characters can be string togeather to make an xpath string that will bring us to where we want to be in the html text. For example, the xpath string\n",
    "\n",
    "`//body/div[@class='title']/@text`\n",
    "\n",
    "is saying: \n",
    "* from the beginning of the html text  for every tag called body' (`//body`), \n",
    "* find an immidiate child of 'body' called 'div' (`/div`) \n",
    "* that has a property called 'class' with a value of 'title' (`[@class='title']`)\n",
    "* and navigate from the found 'div' tags to the value of the property 'text' (`/@text`)\n",
    "\n",
    "When we pass the Selector a text object (in this case the stored html text) and than pass the selector an xpath string, the selector will navigate to the part of the html text as per the instructions in the xpath string.\n",
    "\n",
    "To actually get the value from the text that we navigated to, we need to call `extract()` on the returned value.\n",
    "\n",
    "For an indepth look into XPath and Selectors, the Scrapy [Selectors](https://doc.scrapy.org/en/latest/topics/selectors.html) page is a great resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets take a look at the entire HTML text by running this cell\n",
    "# (If the output takes up the entire page, right click this cell and \"enable scrolling for outputs, if you wish\")\n",
    "\n",
    "print(thread_html_text)\n",
    "\n",
    "#You can right click on this cell and select \"clear outputs\" (for the cell) or \"clear all outputs\" (for the entire notebook). \n",
    "# It does not run or un-run any code, just removes the currently displayed cell outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Lets play around with Selectors and XPath to get our feet wet. \n",
    "\n",
    "print(Selector(text = thread_html_text).xpath(\"//a[@class='forumtitle']\").extract())\n",
    "# Try running the above line of code in the following variations:\n",
    "# Selector(text = thread_html_text) will print the Selector object\n",
    "# Selector(text = thread_html_text).xpath(\"//head\") will print the SelectorList object (a subclass of list that implements the Selector interface) returned by the .xpath(query) method\n",
    "# Selector(text = thread_html_text).xpath(\"//head\").extract() will, for each object in the SelectorList, return the selected part of the HTML text as a list of text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets further refine our XPath query to extract the title of the thread. \n",
    "\n",
    "If you search through the text of the above cell output, you will see that the thread title (which we confirmed by looking at the [thread](https://learningautomaton.ca/wp-content/uploads/2019/02/FruitsAndVeggiesForum/Bears.%20Beets.%20-%20Fruits%20and%20Veggies.html) in our web browser) is \"Bears. Beets.\". \n",
    "\n",
    "This text appears in a few places. We will extract it from \n",
    "`<h2 class=\"topic-title\"><a href=\"./viewtopic.php?f=3&amp;t=7\">Bears. Beets.</a></h2>`\n",
    "\n",
    "To extract this text, we can use the following XPath:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:40 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:40 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:42 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:42 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:43 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:43 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:43 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:44 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:44 am\\n\\t\\t\\t'>,\n",
       " <Selector xpath=\"//div[@class='postbody']//p[@class='author']/text()[3]\" data='Wed Feb 06, 2019 12:44 am\\n\\t\\t\\t'>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Selector(text = thread_html_text).xpath(\"//div[@class='postbody']//p[@class='author']/text()[3]\")\n",
    "# Adding /text() at the end will remove anything that is HTML, and not text content. Try removing /text() and see the output.\n",
    "# Selector(text = thread_html_text).xpath(\"//head/title\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, progress!\n",
    "\n",
    "You should have gotten `['Bears. Beets.']` as the output of the above cell. Note that it appears in brackets as `.extract()` returns a list of outputs, in this case, 1 of 1 pieces of text that matched our selector.\n",
    "\n",
    "Let's make a thread object, and a function to pull what data we can about the thread:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a thread object that we will use to store the information on the entire thread, to include the posts it contains.\n",
    "# we are avoiding any complex or custom data types so that the object is easily serializable later on.\n",
    "class Thread:\n",
    "    def __init__(self):\n",
    "        self.title = None\n",
    "        self.posts = []\n",
    "        self.url = None\n",
    "        self.op_account_name = None\n",
    "\n",
    "def extract_thread_data(html_text):\n",
    "    new_thread = Thread()\n",
    "    new_thread.title = Selector(text = html_text).xpath(\"//h2[@class='topic-title']/a/text()\").extract()[0]\n",
    "    new_thread.url = thread_url\n",
    "    return new_thread\n",
    "\n",
    "print(extract_thread_data(thread_html_text).__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This forum code does not keep information on the thread starter (aka original poster, or \"op\") so we will need to get that information from the posts in the thread.\n",
    "\n",
    "Let's try and find the parts of the HTML file that we can use to extract the post.\n",
    "\n",
    "Looking through the HTML file we notice a tag, `postbody`, let's see what we get by extracting that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selector(text = thread_html_text).xpath(\"//div[@class='postbody']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that returned four items, and we see there are four posts. Let's extract one for a closer look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use print() here to make it more readable\n",
    "print(Selector(text = thread_html_text).xpath(\"//div[@class='postbody']\").extract()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We quickly see that the post title, poster, and content are here. Let's try to extract them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the [0] at the end is to select the bit from the first post, as the Selector returns a list of all matching tags, i.e. the bit for all posts in this thread.\n",
    "post_title = Selector(text = thread_html_text).xpath(\"//div[@class='postbody']//h3/a//text()\").extract()[2] \n",
    "post_user = Selector(text = thread_html_text).xpath(\"//div[@class='postbody']//span[@class='username']//text()\").extract()[2] \n",
    "post_content = Selector(text = thread_html_text).xpath(\"//div[@class='postbody']//div[@class='content']\").extract()[2] \n",
    "#Note: Because of how the website uses <br> tags, using /text() wont work with the post content. We will strip out the HTML tags later. \n",
    "print(\"title:\",post_title)\n",
    "print(\"user:\",post_user)\n",
    "print(\"content:\")\n",
    "print(post_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, we're in business. Now we make a Post class, get the data for all the posts, and store them in the thread.\n",
    "\n",
    "Let's also use Scrapy's `remove_tags` function that we imported earlier to clean up the post content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post:\n",
    "    def __init__(self):\n",
    "        self.user = None\n",
    "        self.title = None\n",
    "        self.content = None\n",
    "    \n",
    "def extract_post_data(html_text):\n",
    "    post_titles = Selector(text = html_text).xpath(\"//div[@class='postbody']//h3/a/text()\").extract()\n",
    "    post_users = Selector(text = html_text).xpath(\"//div[@class='postbody']//span[@class='username']/text()\").extract()\n",
    "    post_contents = Selector(text = html_text).xpath(\"//div[@class='postbody']//div[@class='content']\").extract()\n",
    "    posts = []\n",
    "    for title, author, content in zip(post_titles, post_users, post_contents):\n",
    "        new_post = Post()\n",
    "        new_post.user = author\n",
    "        new_post.title = title\n",
    "        new_post.content = ''.join(remove_tags(content)) #We use join here as content is a list, which we want to flatten into a string\n",
    "        posts.append(new_post)\n",
    "    return posts\n",
    "\n",
    "\n",
    "for _post in extract_post_data(thread_html_text):\n",
    "    print(_post.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, time to wrap everything together in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_thread(html_text):\n",
    "    thread = extract_thread_data(html_text)\n",
    "    thread.posts = extract_post_data(html_text)\n",
    "    thread.op_account_name = thread.posts[0].user\n",
    "    return thread\n",
    "\n",
    "#Yes I know I should be modifying the thread __str__ and __repr__, streach goals.\n",
    "def print_thread(thread):\n",
    "    print(\"Thread title:\", thread.title)\n",
    "    print(\"Thread url:\", thread.url)\n",
    "    print(\"Thread op_account_name:\", thread.op_account_name)\n",
    "    print(\"Posts:\")\n",
    "    for post in thread.posts:\n",
    "        print(\"\\nPost title:\", post.title)\n",
    "        print(\"Post user:\", post.user)\n",
    "        print(\"Post content:\")\n",
    "        print(\"''\\n\",post.content,\"\\n''\")\n",
    "        \n",
    "thread = scrape_thread(thread_html_text)\n",
    "print_thread(thread) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! Checking our results against the [forum page](https://learningautomaton.ca/wp-content/uploads/2019/02/FruitsAndVeggiesForum/Bears.%20Beets.%20-%20Fruits%20and%20Veggies.html) shows that we accurately  extracted all of the data. \n",
    "\n",
    "Let's try it against a different [forum page](https://learningautomaton.ca/wp-content/uploads/2019/02/FruitsAndVeggiesForum/I'm%20Going%20To%20The%20Country,%20I'm%20Gonna%20Eat%20Me%20A%20Lot%20of%20Peaches%20-%20Fruits%20and%20Veggies.html) to ensure our Selectors work across different pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_url2 = \"https://learningautomaton.ca/wp-content/uploads/2019/02/FruitsAndVeggiesForum/I'm%20Going%20To%20The%20Country,%20I'm%20Gonna%20Eat%20Me%20A%20Lot%20of%20Peaches%20-%20Fruits%20and%20Veggies.html\"\n",
    "# use requests to fetch the page as a requests object\n",
    "request_file2 = requests.get(thread_url2)\n",
    "\n",
    "# extract the raw html (the \"text\" property) from the requests object2\n",
    "thread_html_text2 = request_file2.text\n",
    "thread2 = scrape_thread(thread_html_text2)\n",
    "print_thread(thread2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, we have seen:\n",
    "* The basics of XPath and Selectors\n",
    "* How to explore an HTML source file to find the data you want to extract\n",
    "* An example of pulling everything together to extract all of the data we need from a thread\n",
    "\n",
    "The final source code can be found on GitHub here #TODO\n",
    "\n",
    "If you have any comments or recommendations, please let me know by leaving a comment at https://learningautomaton.ca/forum-scrape-project---html-exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><code>if can_learn: \n",
    "    learn()</code></pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
