{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will go through the process of examining a forum webpage for the data we want to extract, and the HTML tags and properties that we can use to identify that data.\n",
    "\n",
    "For the main program we intend to use scrapy to fetch the webpages and extract the data, for simplicity during exploration we only use scrapy to extract the data, and use requests to fetch the website we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scrapy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e04aef91f79c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# import scrapy to develop the Selectors that extract the data we want, to prove they work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscrapy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# TODO Remove htmltotext?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhtml2text\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhtml2text\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scrapy'"
     ]
    }
   ],
   "source": [
    "# import requests to fetch the website (there are many ways of doing this)\n",
    "import requests\n",
    "# import scrapy to develop the Selectors that extract the data we want, to prove they work\n",
    "import scrapy\n",
    "# TODO Remove htmltotext?\n",
    "from html2text import html2text\n",
    "\n",
    "# we import scrapy.selector as Selector for ease of use later\n",
    "from scrapy.selector import Selector\n",
    "#from scrapy.http import HtmlResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the page from the test forum that I will use to explore the data. \n",
    "# The selectors should be tried against multiple web pages to catch inconsistancies, especially is the site had\n",
    "# complex mechanics like quotes, code blocks, and other forms of media. \n",
    "thread_url = \"http://fruitsandveggies.forumotion.com/t4-bears-beets\"\n",
    "\n",
    "# use requests to fetch the page as a requests object\n",
    "request_file = requests.get(thread_url)\n",
    "\n",
    "# extract the raw html (the \"text\" property) from the requests object\n",
    "thread_html_text = request_file.text\n",
    "\n",
    "# note that the two steps could be combined for brevity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a thread object that we will use to store the information on the enture thread, to include the posts it contains.\n",
    "# we are avoiding any complex or custom data types, so that the object is easilly serializable later on.\n",
    "class thread:\n",
    "    def __init__(self):\n",
    "        self.title = None\n",
    "        self.time_created = None\n",
    "        self.posts = []\n",
    "        self.url = None\n",
    "        self.op_account_name = None\n",
    "        self.op_account_link = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tool that scrapy uses to extract a particular part of an html response is Selectors. \n",
    "We also make use of xpath strings. Xpath strings are one method of navigating through an html text to a particular\n",
    "tag. \n",
    "\n",
    "Xpath has a number of options, however the key characters we will be using are:\n",
    "\n",
    "`/tag_name` : from the tag we are at, search for a tag that is an immidiate child that is called `tag_name`\n",
    "`//tag_name` : from the tag we are at, search for all contained tags that are called `tag_name`\n",
    "`@property_name` : extract the value of the tag property called `property_name` from the tag we are currently at\n",
    "`/tag_name[@property_name='property_value']` : go to a child tag that has a property called `property_name` and a value of `property_value`\n",
    "\n",
    "These key characters can be string togeather to make an xpath string that will bring us to where we want to be in the html text. For example, the xpath string\n",
    "\n",
    "`//body/div[@class='title']/@text`\n",
    "\n",
    "is saying: \n",
    "* from the beginning of the html text  for every tag called body' (`//body`), \n",
    "* find an immidiate child of 'body' called 'div' (`/div`) \n",
    "* that has a property called 'class' with a value of 'title' (`[@class='title']`)\n",
    "* and navigate from the found 'div' tags to the value of the property 'text' (`/@text`)\n",
    "\n",
    "When we pass the Selector a text object (in this case the stored html text) and than pass the selector an xpath string, the selector will navigate to the part of the html text as per the instructions in the xpath string.\n",
    "\n",
    "To actually get the value from the text that we navigated to, we need to call `extract()` on the returned value.\n",
    "\n",
    "#insert examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_thread = thread()\n",
    "\n",
    "\n",
    "new_thread.title = Selector(text = thread_html_text).xpath(\"//meta[@name='title']/@content\").extract()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author_account_name': 'DwightLight', 'title': 'Bears. Beets.', 'content': 'Battlestar Galactica.'}\n",
      "{'author_account_name': 'Schrute Farms Official', 'title': 'NO ONE READ THE ABOVE, THAT IS NOT ME', 'content': 'Identity theft is not a joke, Jim! Millions of families suffer every year!'}\n",
      "{'author_account_name': 'DwightLight', 'title': 'Michael!', 'content': '*storms off*'}\n",
      "{'author_account_name': 'Schrute Farms Official', 'title': \"Oh that's funny\", 'content': 'MICHAEL'}\n"
     ]
    }
   ],
   "source": [
    "class post:\n",
    "    def __init__(self):\n",
    "        self.author_account_name = None\n",
    "        self.title = None\n",
    "        self.content = None\n",
    "post_authors = Selector(text = thread_html_text).xpath(\"//body//dl/dt//div[@class='postprofile-name']/text()\").extract()\n",
    "post_title = Selector(text=thread_html_text).xpath(\"//h2[@class='topic-title']//a/text()\").extract()\n",
    "post_contents = Selector(text=thread_html_text).xpath(\"//div[@class='postbody']/div[@class='content']/div/text()\").extract()\n",
    "posts = []\n",
    "for author, title, content in zip(post_authors, post_title, post_contents):\n",
    "    new_post = post()\n",
    "    new_post.author_account_name = author\n",
    "    new_post.title = title\n",
    "    new_post.content = content\n",
    "    posts.append(new_post)\n",
    "for _post in posts:\n",
    "    print(_post.__dict__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
